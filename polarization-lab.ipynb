{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pymetis\n",
    "import copy\n",
    "\n",
    "\n",
    "def read_graphml_file(filename):\n",
    "    \"\"\"Reads a graph from a GraphML file and returns a NetworkX graph object.\"\"\"\n",
    "    try:\n",
    "        # Read the graph from the file\n",
    "        graph = nx.read_graphml(filename)\n",
    "\n",
    "        # Return the graph object\n",
    "        return graph\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_partition(net):\n",
    "    adj_dict = net.get_adjacency_dict()\n",
    "    adj_list = [np.asarray(neighs) for neighs in adj_dict.values()]\n",
    "    n_cuts, membership = pymetis.part_graph(nparts = 2, adjacency = adj_list, options = pymetis.Options(ufactor=400, niter=100, contig=True))\n",
    "    membership = dict(zip(adj_dict.keys(), membership))\n",
    "    return n_cuts, membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialNetwork():\n",
    "\n",
    "    def __init__(self, name, filename):\n",
    "        self.name = name\n",
    "        self.directed_graph = read_graphml_file(filename)\n",
    "        self.undirected_graph = self.directed_graph.to_undirected()\n",
    "\n",
    "        largest_cc = max(nx.connected_components(self.undirected_graph), key=len)\n",
    "        self.giant_component = self.undirected_graph.subgraph(largest_cc).copy()\n",
    "\n",
    "        self.giant_component_int = nx.convert_node_labels_to_integers(self.giant_component, first_label = 0, ordering = 'default', label_attribute = 'user_id')\n",
    "\n",
    "    def get_giant_component_fraction(self):\n",
    "        return len(self.giant_component)/len(self.undirected_graph)\n",
    "\n",
    "    def get_adjacency_dict(self):\n",
    "        adj_list = {}\n",
    "        for node in self.giant_component_int.nodes:\n",
    "            neighbors = list(self.giant_component_int.neighbors(node))\n",
    "            adj_list[node] = neighbors\n",
    "        return adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./keywords_non_universal_stream_processed/CLIMATE_2023_net.graphml\"\n",
    "net = SocialNetwork(name = \"PARTIES2023\", filename = filename)\n",
    "\n",
    "n_cuts, membership = get_partition(net)\n",
    "\n",
    "# ATTRIBUTE 1: Original partition\n",
    "nx.set_node_attributes(net.giant_component_int, membership, name=\"cluster\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_partition(net, membership):\n",
    "\n",
    "    potential_bridge_nodes = []\n",
    "    loner_nodes = []\n",
    "\n",
    "    for node in net.giant_component_int.nodes:\n",
    "        neighbors = net.giant_component_int.neighbors(node)\n",
    "        neighbors_cluster = set([net.giant_component_int.nodes[n][\"cluster\"] for n in neighbors])\n",
    "        if membership[node] not in neighbors_cluster:\n",
    "            loner_nodes.append(node)\n",
    "\n",
    "    membership_finetuned = copy.deepcopy(membership)\n",
    "\n",
    "    c0 = {k for k, v in membership.items() if v == 0}\n",
    "    c1 = {k for k, v in membership.items() if v == 1}\n",
    "\n",
    "    q_best = nx.community.modularity(net.giant_component_int, [c0, c1])\n",
    "    print(f\"Before finetuning modularity is {q_best}\")\n",
    "\n",
    "    for node in loner_nodes:\n",
    "\n",
    "        if membership[node] == 0:\n",
    "            membership_finetuned[node] = 1\n",
    "            new_label = 1\n",
    "        else:\n",
    "            membership_finetuned[node] = 0\n",
    "            new_label = 0\n",
    "        \n",
    "        c0_candidate = {k for k, v in membership_finetuned.items() if v == 0}\n",
    "        c1_candidate = {k for k, v in membership_finetuned.items() if v == 1}\n",
    "\n",
    "        new_q = nx.community.modularity(net.giant_component_int, [c0_candidate, c1_candidate])\n",
    "        \n",
    "        if new_q > q_best:\n",
    "            print(f\"Improvement {new_q - q_best} by swapping node {node}\")\n",
    "            membership[node] = new_label\n",
    "            q_best = new_q\n",
    "\n",
    "        else:\n",
    "            print(f\"No improvement by swapping node {node}\")\n",
    "            membership_finetuned[node] = 1-new_label\n",
    "            \n",
    "    print(f\"After finetuning modularity is {q_best}\")\n",
    "    return membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before finetuning modularity is 0.4514598003065425\n",
      "Improvement 0.00013978125784591677 by swapping node 331\n",
      "Improvement 0.00020961512664796622 by swapping node 677\n",
      "Improvement 0.00013970557768455683 by swapping node 1758\n",
      "Improvement 0.0001396753056202571 by swapping node 2657\n",
      "Improvement 6.982630078578023e-05 by swapping node 2878\n",
      "Improvement 0.00013962989752347443 by swapping node 3095\n",
      "Improvement 6.980359673747216e-05 by swapping node 3149\n",
      "Improvement 0.00020936538211580036 by swapping node 3290\n",
      "Improvement 6.977332467295039e-05 by swapping node 3470\n",
      "Improvement 0.00013952394529770373 by swapping node 3475\n",
      "Improvement 6.97506206245313e-05 by swapping node 3625\n",
      "Improvement 0.0002092064537770888 by swapping node 4099\n",
      "Improvement 6.972034856012055e-05 by swapping node 4142\n",
      "Improvement 6.971278054396235e-05 by swapping node 4711\n",
      "After finetuning modularity is 0.45320489022498006\n"
     ]
    }
   ],
   "source": [
    "membership_original = copy.deepcopy(membership)\n",
    "membership = finetune_partition(net, membership)\n",
    "\n",
    "# ATTRIBUTE 2: Finetuned partition\n",
    "nx.set_node_attributes(net.giant_component_int, membership, name=\"finetuned_cluster\")\n",
    "#nx.write_graphml_lxml(net.giant_component_int, \"simulation-PARTIES-4.graphml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTRIBUTE 3: Candidate information\n",
    "import pandas as pd\n",
    "\n",
    "candidates = pd.read_csv(\"candidates-2023.csv\")\n",
    "candidates_full = pd.read_csv(\"candidates2023-complete.csv\")\n",
    "\n",
    "id_2_candidate = dict(zip(candidates.id.astype(str), candidates.screen_name))\n",
    "candidate_2_id = dict(zip(candidates.screen_name, candidates.id.astype(str)))\n",
    "\n",
    "candidates_full['twitter_id'] = candidates_full['screen_name'].map(candidate_2_id)\n",
    "\n",
    "id_2_party = dict(zip(candidates_full.twitter_id, candidates_full.puolue))\n",
    "id_2_age = dict(zip(candidates_full.twitter_id, candidates_full.ikÃ¤))\n",
    "id_2_sex = dict(zip(candidates_full.twitter_id, candidates_full.sukupuoli))\n",
    "id_2_hometown = dict(zip(candidates_full.twitter_id, candidates_full.kotikunta))\n",
    "id_2_lang = dict(zip(candidates_full.twitter_id, candidates_full.kieli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with node 705853130915889154\n",
      "Error with node 2311345552\n",
      "Error with node 833352107096997890\n"
     ]
    }
   ],
   "source": [
    "screen_name_attributes = dict()\n",
    "party_attributes = dict()\n",
    "sex_attributes = dict()\n",
    "language_attributes = dict()\n",
    "\n",
    "for node in net.giant_component_int.nodes():\n",
    "    node_user_id = net.giant_component_int.nodes[node][\"user_id\"]\n",
    "    try:\n",
    "        if node_user_id in id_2_candidate.keys():\n",
    "            screen_name_attributes[node] = id_2_candidate[node_user_id].rstrip()\n",
    "            party_attributes[node] = id_2_party[node_user_id].rstrip()\n",
    "            sex_attributes[node] = id_2_sex[node_user_id]\n",
    "            language_attributes[node] = id_2_lang[node_user_id]\n",
    "        else:\n",
    "            screen_name_attributes[node] = \"NA\"\n",
    "            party_attributes[node] = \"NA\"\n",
    "            sex_attributes[node] = \"NA\"\n",
    "            language_attributes[node] = \"NA\"\n",
    "    except:\n",
    "        screen_name_attributes[node] = \"NA\"\n",
    "        party_attributes[node] = \"NA\"\n",
    "        sex_attributes[node] = \"NA\"\n",
    "        language_attributes[node] = \"NA\"\n",
    "        print(f\"Error with node {node_user_id}\")\n",
    "\n",
    "nx.set_node_attributes(net.giant_component_int, screen_name_attributes, \"screen_name\")\n",
    "nx.set_node_attributes(net.giant_component_int, party_attributes, \"party\")\n",
    "nx.set_node_attributes(net.giant_component_int, sex_attributes, \"sex\")\n",
    "nx.set_node_attributes(net.giant_component_int, language_attributes, \"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '798095178',\n",
       " 'cluster': 1,\n",
       " 'finetuned_cluster': 1,\n",
       " 'screen_name': 'MariaOhisalo',\n",
       " 'party': 'vihr',\n",
       " 'sex': 2,\n",
       " 'language': 'fi'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.giant_component_int.nodes(data=True)[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(net.giant_component_int, \"./networks/RICH_CLIMATE_2023_NET.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def swap_node(c0, c1, bridge_nodes):\n",
    "\n",
    "    index = random.randint(0, len(bridge_nodes) - 1)\n",
    "\n",
    "    if bridge_nodes[index] in c0:\n",
    "        c0.remove(bridge_nodes[index])\n",
    "        c1.append(bridge_nodes[index])\n",
    "    else:\n",
    "        c1.remove(bridge_nodes[index])\n",
    "        c0.append(bridge_nodes[index])\n",
    "\n",
    "    return c0, c1\n",
    "\n",
    "cluster0_before_finetuning = cluster0_best = cluster0_candidate = list({k for k, v in membership.items() if v == 0})\n",
    "cluster1_before_finetuning = cluster1_best = cluster1_candidate = list({k for k, v in membership.items() if v == 1})\n",
    "\n",
    "q_before_finetuning = q_best = nx.community.modularity(net.giant_component_int, [cluster0_best, cluster1_best])\n",
    "\n",
    "for node in potential_bridge_nodes:\n",
    "    cluster0_candidate = cluster0_best\n",
    "    cluster1_candidate =  cluster1_best\n",
    "    #cluster0, cluster1 = swap_node(cluster0_best, cluster1_best, potential_bridge_nodes)\n",
    "    if node in cluster0_best:\n",
    "        cluster0_candidate.remove(node)\n",
    "        cluster1_candidate.append(node)\n",
    "    else:\n",
    "        cluster1_candidate.remove(node)\n",
    "        cluster0_candidate.append(node)\n",
    "\n",
    "    new_q = nx.community.modularity(net.giant_component_int, [cluster0_candidate, cluster1_candidate])\n",
    " \n",
    "    if new_q > q_best:\n",
    "        print(f\"Improvement {new_q - q_best}\")\n",
    "        cluster0_best = cluster0_candidate\n",
    "        cluster1_best = cluster1_candidate\n",
    "\n",
    "        q_best = new_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_best, q_before_finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _ in range(500):\n",
    "    set1, set2 = swap_node(set1_best, set2_best)\n",
    "    \n",
    "\n",
    "    if new_q > best_q:\n",
    "        set1_best = set1\n",
    "        set2_best = set2\n",
    "        best_q = new_q\n",
    "        print(\"bingo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sets = [cluster0_before_finetuning, cluster1_before_finetuning]\n",
    "\n",
    "original_q = nx.community.modularity(net.giant_component_int, sets)\n",
    "best_q = nx.community.modularity(net.giant_component_int, sets)\n",
    "\n",
    "import random\n",
    "\n",
    "def swap_sets(set1, set2):\n",
    "    \n",
    "    set1_list = list(set1)\n",
    "    set2_list = list(set2)\n",
    "    \n",
    "    index = random.randint(0, len(set1) - 1)\n",
    "    set1_list[index], set2_list[index] = set2_list[index], set1_list[index]\n",
    "    \n",
    "    return set(set1_list), set(set2_list)\n",
    "\n",
    "\n",
    "for _ in range(5000):\n",
    "    set1, set2 = swap_sets(cluster0_before_finetuning, cluster1_before_finetuning)\n",
    "    sets = [set1, set2]\n",
    "    new_q = nx.community.modularity(net.giant_component_int, sets)\n",
    "\n",
    "    if new_q > best_q:\n",
    "        set1_best = set1\n",
    "        set2_best = set2\n",
    "        best_q = new_q\n",
    "        print(\"bingo\")\n",
    "\n",
    "\n",
    "print(f\"The best modularity was before the finetuning {original_q}, now it is {best_q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_membership = dict()\n",
    "\n",
    "for node in net.giant_component_int.nodes:\n",
    "    if node in set1_best:\n",
    "        finetuned_membership[node] = 1\n",
    "\n",
    "    else:\n",
    "        finetuned_membership[node] = 0\n",
    "\n",
    "\n",
    "nx.set_node_attributes(net.giant_component_int, membership, name=\"finetuned_cluster\")\n",
    "nx.write_graphml_lxml(net.giant_component_int, \"simulation-climate-3.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short sim\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# add nodes to the graph\n",
    "for i in range(1, 8):\n",
    "    G.add_node(i)\n",
    "\n",
    "# add edges to the graph to create a chain\n",
    "G.add_edges_from([(1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7)])\n",
    "\n",
    "# draw the graph using matplotlib\n",
    "colors = [\"b\", \"b\", \"b\", \"g\", \"g\", \"g\", \"g\"]\n",
    "nx.draw(G, with_labels=True, node_color=colors)\n",
    "\n",
    "nx.community.modularity(G, [{1, 2, 3, 4}, {4, 5, 6, 7}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac2a544d231e065a983bc013f13eb04c003f8cab54895e1be78107126ab5a16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
