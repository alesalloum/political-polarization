{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for creating an edgelist from the users_stream gzip files\n",
    "Author: Ali Salloum 23.3.2023\n",
    "\n",
    "- The mapping from the author_id to the nickname can be done with the candidate2023 list.\n",
    "- First node represents the retweeter, second node the retweeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory\n",
    "data_dir = \"../users_stream\"\n",
    "\n",
    "# Load the data\n",
    "twitter_files = sorted(os.listdir(data_dir))\n",
    "\n",
    "raw_data = []\n",
    "\n",
    "for tweets_file in tqdm(twitter_files):\n",
    "  with gzip.open(filename = os.path.join(data_dir, tweets_file), mode = 'rb') as f_tweets:\n",
    "        for line in f_tweets:\n",
    "          tweet = json.loads(line)\n",
    "          raw_data.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def remove_duplicates(data):\n",
    "\n",
    "    print(f\"Number of json objects found is {len(raw_data)}.\")\n",
    "    \n",
    "    no_duplicates = []\n",
    "\n",
    "    for obj in tqdm(data):\n",
    "        if obj not in no_duplicates:\n",
    "            no_duplicates.append(obj)\n",
    "\n",
    "    print(f\"After removing the duplicates, we are left with {len(data)} objects.\")\n",
    "\n",
    "    return no_duplicates\n",
    "\n",
    "def check_retweet_status(obj):\n",
    "    if \"referenced_tweets\" in obj:\n",
    "        if obj[\"referenced_tweets\"][0][\"type\"] == \"retweeted\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def edge_formation(data):\n",
    "    \n",
    "    data = remove_duplicates(data)\n",
    "\n",
    "    edge_data = []\n",
    "\n",
    "    for obj in tqdm(data):\n",
    "        if check_retweet_status(obj):\n",
    "            retweeter_node = obj[\"author_id\"]\n",
    "            retweeted_node = obj[\"referenced_tweets\"][0][\"tweet\"][\"author_id\"]\n",
    "            timestamp = obj[\"created_at\"]\n",
    "\n",
    "            edge_data.append([retweeter_node, retweeted_node, timestamp])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the edge list\n",
    "edge_list = edge_formation(raw_data)\n",
    "\n",
    "# Convert it to pandas dataframe object and save it \n",
    "df = pd.DataFrame(edge_list)\n",
    "df.to_csv(\"./users_stream_edgelist.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./users_stream_processed/users_stream_edgelists.txt\")\n",
    "df.columns = [\"source\", \"target\", \"timestamp\"]\n",
    "\n",
    "df_weights = df.value_counts([\"source\", \"target\"]).reset_index()\n",
    "df_weights.columns = [\"source\", \"target\", \"weight\"]\n",
    "\n",
    "G = nx.from_pandas_edgelist(df_weights, edge_attr = \"weight\", create_using = nx.DiGraph())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = pd.read_csv(\"candidates-2023.csv\")\n",
    "candidates_full = pd.read_csv(\"candidates2023-complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2_candidate = dict(zip(candidates.id, candidates.screen_name))\n",
    "\n",
    "candidate_2_party = dict(zip(candidates_full.screen_name, candidates_full.puolue))\n",
    "candidate_2_age = dict(zip(candidates_full.screen_name, candidates_full.ik√§))\n",
    "candidate_2_sex = dict(zip(candidates_full.screen_name, candidates_full.sukupuoli))\n",
    "candidate_2_hometown = dict(zip(candidates_full.screen_name, candidates_full.kotikunta))\n",
    "candidate_2_lang = dict(zip(candidates_full.screen_name, candidates_full.kieli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add screen_names\n",
    "for node in G.nodes():\n",
    "    if node in id_2_candidate:\n",
    "        G.nodes[node][\"screen_name\"] = id_2_candidate[node]\n",
    "    else:\n",
    "        G.nodes[node][\"screen_name\"] = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_attributes = dict()\n",
    "sex_attributes = dict()\n",
    "language_attributes = dict()\n",
    "\n",
    "for node in G.nodes():\n",
    "    node_screen_name = G.nodes[node][\"screen_name\"]\n",
    "    if node_screen_name in candidate_2_party:\n",
    "        party_attributes[node] = candidate_2_party[node_screen_name].rstrip()\n",
    "        sex_attributes[node] = candidate_2_sex[node_screen_name]\n",
    "        language_attributes[node] = candidate_2_lang[node_screen_name]\n",
    "    else:\n",
    "        party_attributes[node] = \"NA\"\n",
    "        sex_attributes[node] = \"NA\"\n",
    "        language_attributes[node] = \"NA\"\n",
    "\n",
    "nx.set_node_attributes(G, party_attributes, \"party\")\n",
    "nx.set_node_attributes(G, sex_attributes, \"sex\")\n",
    "nx.set_node_attributes(G, language_attributes, \"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(G, \"candidates-full.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gcc = sorted(nx.connected_components(G.to_undirected()), key=len, reverse=True)\n",
    "G0 = G.subgraph(Gcc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml_lxml(G0, \"candidates-full-gc.graphml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac2a544d231e065a983bc013f13eb04c003f8cab54895e1be78107126ab5a16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
